___

                            Ray Core - Intro

_____

Ray Core provides a small number of low level primitives to distribute your 
computations.

* Get Started

  To use *only* ray core, simply `pip install ray`. 

  To initialize ray we use `ray.init()`.
  @code python
  import ray 
  ray.init()
  @end
* Tasks

  Ray enables functions to be executed asynchronously on separate python 
  workers. These are called "tasks". Tasks can specify resource requirements 
  which is used by the scheduler to distribute them in the cluster for parallel
  execution.

  To run functions as remote tasks in a Ray cluster, use the decorator 
  `@ray.remote`. Then, to call the function, append `.remote()` to the call. 
  Arguments to the function should be passed inside `.remote()`.

  This will return a future (a Ray *object reference*) that you can fetch with
  `ray.get` which will fetch the result once it is completed.
  @code python 
  # Define the square task.
  @ray.remote
  def square(x):
      return x * x

  # Launch four parallel square tasks.
  futures = [square.remote(i) for i in range(4)]

  # Retrieve results.
  print(ray.get(futures))
  # -> [0, 1, 4, 9]
  @end

* Actors

  Actors are stateful entities that can perform some computation while 
  maintaining an internal state across remote calls. 
  Conceptually:
  - Actors -> classes (stateful)
  - Tasks -> functions (not stateful)

  When you instantiate a class which is a Ray Actor, Ray creates a new worker 
  which will start a remote instance of that class that can execute methods 
  remotely. All method calls on this instance will be scheduled on that 
  specific worker.
  @code python
  # Define the Counter actor.
  @ray.remote
  class Counter:
      def __init__(self):
          self.i = 0

  def get(self):
      return self.i

  def incr(self, value):
      self.i += value

  # Create a Counter actor.
  c = Counter.remote()

  # Submit calls to the actor. These calls run asynchronously but in
  # submission order on the remote actor process.
  for _ in range(10):
      c.incr.remote(1)

  # Retrieve final actor state.
  print(ray.get(c.get.remote()))
  # -> 10
  @end
* Objects

  Ray stores the results of remote calls (tasks and actors) in a *distributed 
  object store*. We use *object references* to refer to objects and there is 
  one *object store* per node. 

  Tasks and actors operate on objects. In fact, all remote calls return 
  *object references*, which can later be retreived with `ray.get()`.

  Important: *Object references* can also be explicitly created by `ray.put` which 
  puts data in the *object store* and returns an *object reference*.

  *Object references* can be passed to tasks as substitutes for argument values. 
  In certain conditions, Ray automatically dereferences the *object reference*,
  so it's the same as using the values. 
  @code python
  import numpy as np
  
  # Define a task that sums the values in a matrix.
  @ray.remote
  def sum_matrix(matrix):
      return np.sum(matrix)
  
  # Call the task with a literal argument value.
  print(ray.get(sum_matrix.remote(np.ones((100, 100)))))
  # -> 10000.0
  
  # Put a large array into the object store.
  matrix_ref = ray.put(np.ones((1000, 1000)))
  
  # Call the task with the object reference as an argument.
  print(ray.get(sum_matrix.remote(matrix_ref)))
  # -> 1000000.0
  @end
* Placement Groups

  Ray allows users to reserve groups of resources across multiple nodes. 
  They can then be used to schedule Ray tasks and actors inside specific groups.

* Environment Dependencies

  When Ray executes tasks and actors on remote machines, it expects that 
  the environment is properly set everywhere. It is our responsability to do 
  this. Two solutions are:
  ~ Use Ray's cluster launcher.
  ~ Use Ray's runtime environment.


































